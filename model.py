# -*- coding: utf-8 -*-
"""RA1911026010113_Raghav_Khatoria_final_assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17XKkSfvTf__Bsh5jC9oxz3X8BhzmaMo_

#Final Assignment

Problem Statement - To predict the insurance premium (Charges) using various ML models. Dataset used is https://www.kaggle.com/simranjain17/insurance, which consists of 7 attributes - Age, Gender, Region, BMI, Children, Smoker, Charges.

## Importing the libraries
"""
from flask import Flask,request,render_template
import numpy as np
import pickle
import pandas as pd


"""## Importing the dataset"""
print('hello')
dataset = pd.read_csv('./insurance.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
print('kk')
#Here as the values of Sex,Smoker and region are in categorical format so we have to change them 
#Applying OneHotEncoding for Region column
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [-1])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

#Applying Binary Encoding for Gender and Smoker column
X[:,5] = (X[:,5] == 'male').astype(int)    #For Gender
X[:,-1] = (X[:,-1] == 'yes').astype(int)   #For Smoker


"""##Training the model on Multivariate linear Regression"""

from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold 
k = 10
kf = KFold(n_splits=10, random_state=None)
model = LinearRegression()
 
acc_score = []
 
for train_index , test_index in kf.split(X):
    X_train , X_test = X[train_index,:],X[test_index,:]
    y_train , y_test = y[train_index] , y[test_index]
    model.fit(X_train,y_train)
    pred_values = model.predict(X_test)
    acc = r2_score(pred_values , y_test)
    acc_score.append(acc)

avg_acc_score = sum(acc_score)/k
 
print('Accuracy of each fold - {}'.format(acc_score))
print('Avg accuracy : {}'.format(avg_acc_score))

"""## Training the Decision Tree Regression model"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold 
k = 10
kf = KFold(n_splits=10, random_state=None)
model2 = DecisionTreeRegressor(random_state = 0,min_samples_leaf=25, min_samples_split=3)
 
acc_score = []
 
for train_index , test_index in kf.split(X):
    X_train , X_test = X[train_index,:],X[test_index,:]
    y_train , y_test = y[train_index] , y[test_index]
    model2.fit(X_train,y_train)
    pred_values = model2.predict(X_test)
    acc = r2_score(pred_values , y_test)
    acc_score.append(acc)

avg_acc_score = sum(acc_score)/k
 
print('Accuracy of each fold - {}'.format(acc_score))
print('Avg accuracy : {}'.format(avg_acc_score))

"""## Training the Random Forest Tree Regression model"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold 
k = 10
kf = KFold(n_splits=10, random_state=None)
model3 = RandomForestRegressor(n_estimators = 80, random_state=0, min_samples_leaf=15, min_samples_split=2)
 
acc_score = []
 
for train_index , test_index in kf.split(X):
    X_train , X_test = X[train_index,:],X[test_index,:]
    y_train , y_test = y[train_index] , y[test_index]
    model3.fit(X_train,y_train)
    pred_values = model3.predict(X_test)
    acc = r2_score(pred_values , y_test)
    acc_score.append(acc)

avg_acc_score = sum(acc_score)/k
 
print('Accuracy of each fold - {}'.format(acc_score))
print('Avg accuracy : {}'.format(avg_acc_score))


pickle.dump(model3,open('model.pkl','wb'))
"""Accuracies given by different models


*   Multivariate Linear Regression - 66.3%
*   Decision Tree Regression - 83.07%
*   Random Forest Regression - 83.64%

Now here we observe that the best prediction was given by the Random forest regressor with an accuracy of 83.64%.


"""